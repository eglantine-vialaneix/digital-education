import streamlit as st
from pages.src.utils import assign_condition, init_supabase, save_user_data_to_supabase

###################### STREAMLIT APP ######################

st.set_page_config(page_title="Cauchy in Matterhorn",
                   page_icon="src/assets/gd_icon.png",
                   layout = "wide",
                   )

############################################################

if "PSI" not in st.session_state:
    if "user_key" not in st.session_state:
        user_key = st.text_input(label="Please enter your personal key:",
                                type="password",
                                width="stretch",
                                icon="üîê",
                                max_chars=4
                                )
    if user_key:
        st.session_state.user_key = user_key
        st.session_state.PSI = assign_condition(user_key)

st.markdown("Congratulations! You arrived home and your oven is safely off. Most importantly you learnt (we hope!) about Gradient Descent, and helped us running our experiment, so thanks a lot!")

# fallback to EN if not set
lang = st.session_state.get("prefered_language", "EN")

###################### TEXT LABELS ########################

title_labels = {
    "EN": "Post-test",
    "FR": "Post-test",
    "IT": "Post-test",
}

intro_labels = {
    "EN": "Please answer the following questions based on what you learned in the activity.",
    "FR": "Merci de r√©pondre aux questions suivantes en te basant sur ce que tu as appris durant l‚Äôactivit√©.",
    "IT": "Per favore rispondi alle seguenti domande in base a ci√≤ che hai imparato durante l‚Äôattivit√†.",
}

map_label = {
    "EN": "1. Mapping real-world metaphor ‚Üí algorithmic components",
    "FR": "1. Mise en correspondance m√©taphore du monde r√©el ‚Üí composantes de l‚Äôalgorithme",
    "IT": "1. Mappatura della metafora del mondo reale ‚Üí componenti algoritmici",
}

map_prompt = {
    "EN": (
        "Thinking back to the introductory context video, match each element of the real-world metaphor "
        "to the corresponding part of the gradient descent algorithm.\n\n"
        "**Left elements**:\n"
        "- A) Mountains\n"
        "- B) Point where you were on the mountain\n"
        "- C) Step size\n"
        "- D) Valley\n"
        "- E) Different possible path\n\n"
        "**Right elements**:\n"
        "- 1) Function f()\n"
        "- 2) $a_0$\n"
        "- 3) $\\eta$ (eta)\n"
        "- 4) Minimum\n"
        "- 5) Different possible choice of parameters\n\n"
        "Write your answers in the following form, for example: `(A,1), (B,2), (C,3)`."
    ),
    "FR": (
        "En repensant √† la vid√©o de contexte, associe chaque √©l√©ment de la m√©taphore du monde r√©el "
        "√† la partie correspondante de l‚Äôalgorithme de descente de gradient.\n\n"
        "**√âl√©ments de gauche** :\n"
        "- A) Montagnes\n"
        "- B) Point o√π tu te trouvais sur la montagne\n"
        "- C) Taille du pas\n"
        "- D) Vall√©e\n"
        "- E) Diff√©rents chemins possibles\n\n"
        "**√âl√©ments de droite** :\n"
        "- 1) Fonction f()\n"
        "- 2) $a_0$\n"
        "- 3) $\\eta$ (eta)\n"
        "- 4) Minimum\n"
        "- 5) Diff√©rents choix possibles de param√®tres\n\n"
        "√âcris tes r√©ponses dans la forme suivante, par exemple : `(A,1), (B,2), (C,3)`."
    ),
    "IT": (
        "Ripensando al video introduttivo, abbina ogni elemento della metafora del mondo reale "
        "alla parte corrispondente dell‚Äôalgoritmo di discesa del gradiente.\n\n"
        "**Elementi di sinistra**:\n"
        "- A) Montagna\n"
        "- B) Punto in cui ti trovavi sulla montagna\n"
        "- C) Dimensione del passo\n"
        "- D) Valle\n"
        "- E) Diversi percorsi possibili\n\n"
        "**Elementi di destra**:\n"
        "- 1) Funzione f()\n"
        "- 2) $a_0$\n"
        "- 3) $\\eta$ (eta)\n"
        "- 4) Minimo\n"
        "- 5) Diversa scelta possibile dei parametri\n\n"
        "Scrivi le tue risposte nella seguente forma, ad esempio: `(A,1), (B,2), (C,3)`."
    ),
}

map_input_label = {
    "EN": "Your mapping:",
    "FR": "Tes associations :",
    "IT": "Le tue associazioni:",
}

neg_grad_label = {
    "EN": "2. Reason for moving in the negative gradient direction",
    "FR": "2. Raison de se d√©placer dans la direction oppos√©e au gradient",
    "IT": "2. Motivo per cui ci muoviamo nella direzione negativa del gradiente",
}

neg_grad_prompt = {
    "EN": "In your own words, why do we move in the **negative** direction of the gradient during gradient descent?",
    "FR": "Avec tes propres mots, pourquoi se d√©place-t-on dans la **direction oppos√©e** au gradient lors de la descente de gradient ?",
    "IT": "Con parole tue, perch√© nel Gradient Descent ci muoviamo nella **direzione negativa** del gradiente?",
}

conv_label = {
    "EN": "3. Convergence of Gradient Descent",
    "FR": "3. Convergence de la descente de gradient",
    "IT": "3. Convergenza della discesa del gradiente",
}

conv_question = {
    "EN": "Does gradient descent always converge to a minimum?",
    "FR": "La descente de gradient converge-t-elle toujours vers un minimum ?",
    "IT": "La discesa del gradiente converge sempre a un minimo?",
}

conv_options = {
    "EN": [
        "A. Yes, gradient descent always converges to a global minimum for any function and any step size.",
        "B. No, gradient descent may fail to converge if the function is not convex or if the step size is not appropriate.",
        "C. Yes, gradient descent always converges as long as the gradient exists.",
        "D. No, gradient descent never converges unless the function is quadratic.",
    ],
    "FR": [
        "A. Oui, la descente de gradient converge toujours vers un minimum global pour toute fonction et toute taille de pas.",
        "B. Non, la descente de gradient peut ne pas converger si la fonction n‚Äôest pas convexe ou si la taille du pas n‚Äôest pas appropri√©e.",
        "C. Oui, la descente de gradient converge toujours tant que le gradient existe.",
        "D. Non, la descente de gradient ne converge jamais √† moins que la fonction ne soit quadratique.",
    ],
    "IT": [
        "A. S√¨, la discesa del gradiente converge sempre a un minimo globale per qualsiasi funzione e qualsiasi dimensione del passo.",
        "B. No, la discesa del gradiente potrebbe non convergere se la funzione non √® convessa o se la dimensione del passo non √® appropriata.",
        "C. S√¨, la discesa del gradiente converge sempre finch√© esiste il gradiente.",
        "D. No, la discesa del gradiente non converge mai a meno che la funzione non sia quadratica.",
    ],
}

zero_label = {
    "EN": "4. Interpretation of zero gradient",
    "FR": "4. Interpr√©tation d‚Äôun gradient nul",
    "IT": "4. Interpretazione del gradiente zero",
}

zero_question = {
    "EN": "Suppose the gradient of a convex function is zero at a certain point during the algorithm execution. What does this imply?",
    "FR": "Supposons que le gradient d‚Äôune fonction convexe soit nul en un certain point pendant l‚Äôex√©cution de l‚Äôalgorithme. Qu‚Äôest-ce que cela implique ?",
    "IT": "Supponiamo che il gradiente di una funzione convessa sia zero in un certo punto durante l'esecuzione dell'algoritmo. Cosa implica questo?",
}

zero_options = {
    "EN": [
        "A. The point is a global maximum of the function.",
        "B. The algorithm has diverged.",
        "C. The point is a global or local minimum of the function.",
        "D. The function is non-differentiable at that point.",
    ],
    "FR": [
        "A. Le point est un maximum global de la fonction.",
        "B. L‚Äôalgorithme a diverg√©.",
        "C. Le point est un minimum global ou local de la fonction.",
        "D. La fonction n‚Äôest pas diff√©rentiable en ce point.",
    ],
    "IT": [
        "A. Il punto √® un massimo globale della funzione.",
        "B. L'algoritmo ha divergenza.",
        "C. Il punto √® un minimo globale o locale della funzione.",
        "D. La funzione non √® differenziabile in quel punto.",
    ],
}

# Loss function and loss curve interpretation (open)
loss_label = {
    "EN": "5. Loss function and loss curve interpretation",
    "FR": "5. Interpr√©tation de la fonction de perte et de la courbe de perte",
    "IT": "5. Interpretazione della funzione di perdita e della curva di perdita",
}

loss_prompt = {
    "EN": (
        "Considering the loss curve(s) you saw (for example, one that overshoots with a learning rate $\\eta$ too large, "
        "or one that starts very high because $a_0$ is far and decreases very slowly because $\\eta$ is too small), "
        "describe what the curve reveals about the algorithm‚Äôs behavior."
    ),
    "FR": (
        "En te basant sur la ou les courbes de perte que tu as vues (par exemple, une courbe qui d√©passe le minimum "
        "avec un $\\eta$ trop grand, ou une courbe qui part tr√®s haut car $a_0$ est loin et diminue tr√®s lentement "
        "car $\\eta$ est trop petit), d√©cris ce que cette courbe r√©v√®le du comportement de l‚Äôalgorithme."
    ),
    "IT": (
        "Considerando la curva (o le curve) di perdita che hai visto (ad esempio, una che supera il minimo perch√© $\\eta$ √® troppo grande, "
        "oppure una che parte molto alta perch√© $a_0$ √® lontano e diminuisce molto lentamente perch√© $\\eta$ √® troppo piccolo), "
        "descrivi cosa rivela la curva sul comportamento dell'algoritmo."
    ),
}

multi_intro = {
    "EN": (
        "In the following questions, you will select **one or more** correct answers.\n"
        "Unlike typical multiple-choice questions, there may be multiple correct options, "
        "and not all options carry the same meaning. Read carefully and select **all** the answers that you think are correct."
    ),
    "FR": (
        "Dans les questions suivantes, tu devras s√©lectionner **une ou plusieurs** r√©ponses correctes.\n"
        "Contrairement aux QCM classiques, il peut y avoir plusieurs r√©ponses correctes, "
        "et toutes n‚Äôont pas exactement la m√™me signification. Lis attentivement et s√©lectionne **toutes** les r√©ponses que tu juges correctes."
    ),
    "IT": (
        "Nelle seguenti domande, dovrai selezionare **una o pi√π** risposte corrette.\n"
        "A differenza delle tipiche domande a risposta multipla, potrebbero esserci pi√π opzioni corrette "
        "e non tutte hanno lo stesso significato. Leggi attentamente e seleziona tutte le risposte che ritieni corrette."
    ),
}

a0_label = {
    "EN": "6. In gradient descent, what does the parameter $a_0$ (initial value / starting point) influence?",
    "FR": "6. En descente de gradient, qu‚Äôest-ce que le param√®tre $a_0$ (valeur initiale / point de d√©part) influence ?",
    "IT": "6. Nel Gradient Descent, cosa influenza il parametro $a_0$ (valore iniziale / punto di partenza)?",
}

a0_options = {
    "EN": [
        "A. It may determine whether the algorithm converges to a global minimum or becomes trapped in a local minimum (for non-convex loss surfaces).",
        "B. It affects the number of iterations required to reach convergence, even if the final solution is the same.",
        "C. It can lead the algorithm to converge to a saddle point instead of a minimum.",
        "D. It influences the value of the gradient evaluated at the first iteration and therefore affects all subsequent updates.",
    ],
    "FR": [
        "A. Il peut d√©terminer si l‚Äôalgorithme converge vers un minimum global ou reste bloqu√© dans un minimum local (pour des surfaces de perte non convexes).",
        "B. Il influence le nombre d‚Äôit√©rations n√©cessaires pour atteindre la convergence, m√™me si la solution finale est la m√™me.",
        "C. Il peut amener l‚Äôalgorithme √† converger vers un point selle plut√¥t qu‚Äôun minimum.",
        "D. Il influence la valeur du gradient √©valu√© √† la premi√®re it√©ration et affecte donc toutes les mises √† jour suivantes.",
    ],
    "IT": [
        "A. Pu√≤ determinare se l'algoritmo converge a un minimo globale o rimane intrappolato in un minimo locale (per funzioni non convesse).",
        "B. Influisce sul numero di iterazioni necessarie per raggiungere la convergenza, anche se la soluzione finale √® la stessa.",
        "C. Pu√≤ portare l'algoritmo a convergere a un punto di sella anzich√© a un minimo.",
        "D. Influenza il valore del gradiente valutato alla prima iterazione e quindi influenza tutti gli aggiornamenti successivi.",
    ],
}

eta_label = {
    "EN": "7. In gradient descent, what does the parameter $\\eta$ (learning rate / step size) control?",
    "FR": "7. En descente de gradient, que contr√¥le le param√®tre $\\eta$ (taux d‚Äôapprentissage / taille du pas) ?",
    "IT": "7. Nel Gradient Descent, cosa controlla il parametro $\\eta$ (velocit√† di apprendimento / dimensione del passo)?",
}

eta_options = {
    "EN": [
        "A. A large $\\eta$ can cause oscillations or divergence instead of convergence.",
        "B. A small $\\eta$ increases the number of iterations needed to converge.",
        "C. Different values of $\\eta$ can cause different convergence trajectories on the same loss function.",
        "D. $\\eta$ determines the direction in which the parameter moves at each iteration.",
    ],
    "FR": [
        "A. Un $\\eta$ √©lev√© peut provoquer des oscillations ou une divergence au lieu d‚Äôune convergence.",
        "B. Un petit $\\eta$ augmente le nombre d‚Äôit√©rations n√©cessaires pour converger.",
        "C. Des valeurs diff√©rentes de $\\eta$ peuvent entra√Æner des trajectoires de convergence diff√©rentes sur la m√™me fonction de perte.",
        "D. $\\eta$ d√©termine la direction dans laquelle le param√®tre se d√©place √† chaque it√©ration.",
    ],
    "IT": [
        "A. Un $\\eta$ elevato pu√≤ causare oscillazioni o divergenza anzich√© convergenza.",
        "B. Un piccolo $\\eta$ aumenta il numero di iterazioni necessarie per convergere.",
        "C. Valori diversi di $\\eta$ possono causare traiettorie di convergenza diverse sulla stessa funzione di perdita.",
        "D. $\\eta$ determina la direzione in cui si muove il parametro a ogni iterazione.",
    ],
}

submit_labels = {
    "EN": "Submit my post-test answers",
    "FR": "Soumettre mes r√©ponses au post-test",
    "IT": "Invia le mie risposte al post-test",
}

success_labels = {
    "EN": "Thank you! Your post-test answers have been saved.",
    "FR": "Merci ! Tes r√©ponses au post-test ont √©t√© enregistr√©es.",
    "IT": "Grazie! Le tue risposte al post-test sono state salvate.",
}

congrats_text = {
    "EN": "Congratulations! You arrived home and your oven is safely off. Most importantly, you learnt (we hope!) about Gradient Descent and helped us run our experiment ‚Äì thank you so much! üíô",
    "FR": "F√©licitations ! Tu es bien rentr√©¬∑e chez toi et ton four est √©teint en toute s√©curit√©. Surtout, tu as (on l‚Äôesp√®re !) appris des choses sur la descente de gradient et tu nous as aid√©¬∑es √† mener notre exp√©rience ‚Äì merci beaucoup ! üíô",
    "IT": "Congratulazioni! Sei arrivato/a a casa e il tuo forno √® spento in sicurezza. Soprattutto, hai (speriamo!) imparato qualcosa sulla discesa del gradiente e ci hai aiutato a svolgere il nostro esperimento ‚Äì grazie mille! üíô",
}

###################### FORM LOGIC #########################

if "posttest_submitted" not in st.session_state:
    st.session_state.posttest_submitted = False

st.markdown(f"## {title_labels[lang]}")
st.write(intro_labels[lang])

if not st.session_state.posttest_submitted:
    with st.form("posttest_form"):

        # Q1
        st.markdown(f"### {map_label[lang]}")
        st.markdown(map_prompt[lang])
        map_answer = st.text_input(map_input_label[lang])

        # Q2
        st.markdown(f"### {neg_grad_label[lang]}")
        neg_grad_answer = st.text_area(neg_grad_prompt[lang])

        # Q3
        st.markdown(f"### {conv_label[lang]}")
        st.write(conv_question[lang])
        conv_answer = st.radio(
            label="",
            options=conv_options[lang],
            index=None,
        )

        # Q4
        st.markdown(f"### {zero_label[lang]}")
        st.write(zero_question[lang])
        zero_answer = st.radio(
            label="",
            options=zero_options[lang],
            index=None,
        )

        # Q5
        st.markdown(f"### {loss_label[lang]}")
        loss_answer = st.text_area(loss_prompt[lang])

        st.markdown("---")
        st.markdown(multi_intro[lang])

        # Q6
        st.markdown(f"### {a0_label[lang]}")
        a0_answer = st.multiselect(
            label="",
            options=a0_options[lang],
        )

        # Q7
        st.markdown(f"### {eta_label[lang]}")
        eta_answer = st.multiselect(
            label="",
            options=eta_options[lang],
        )

        submitted = st.form_submit_button(submit_labels[lang])

    if submitted:
        st.session_state.posttest_answers = {
            "mapping_metaphor": map_answer,
            "negative_gradient_reason": neg_grad_answer,
            "convergence_mcq": conv_answer,
            "zero_gradient_mcq": zero_answer,
            "loss_curve_interpretation": loss_answer,
            "a0_influence": a0_answer,
            "eta_control": eta_answer,
        }
        st.session_state.posttest_submitted = True
        st.success(success_labels[lang])
        st.markdown(congrats_text[lang])
else:
    st.success(success_labels[lang])
    st.markdown(congrats_text[lang])

##############

if st.button("FIN"):
    supabase = init_supabase()
    save_user_data_to_supabase(supabase)